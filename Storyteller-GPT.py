#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import torch
from transformers import GPT2Tokenizer, GPT2LMHeadModel, GenerationConfig
import numpy as np
import re

# Definici√≥n de una excepci√≥n personalizada para errores cr√≠ticos de carga
class InterstellarError(Exception):
    """Excepci√≥n personalizada para errores cr√≠ticos, como fallos en la carga del modelo."""
    pass

class StorytellerGPT:
    """
    Clase principal para el Generador de Cuentos M√°gicos.
    Utiliza el modelo GPT-2 en espa√±ol para generar ideas y comienzos de historias.
    """
    def __init__(self):
        # Determina si se usar√° la GPU (cuda) o la CPU. Prioriza 'cuda' si est√° disponible.
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.model_name = "DeepESP/gpt2-spanish" # Modelo pre-entrenado GPT-2 en espa√±ol

        print(f"üöÄ Iniciando StorytellerGPT en el dispositivo: {self.device.upper()}...")
        
        # Intenta cargar el tokenizer y el modelo. Si falla, intenta un respaldo.
        try:
            self.tokenizer = GPT2Tokenizer.from_pretrained(self.model_name)
            self.model = GPT2LMHeadModel.from_pretrained(self.model_name).to(self.device)
            self.tokenizer.pad_token = self.tokenizer.eos_token # Define el token de padding
            print("‚úÖ Modelo GPT-2 para espa√±ol cargado con √©xito.")
        except Exception as e:
            print(f"‚ö° ¬°Alerta C√≥smica! Fall√≥ la carga principal ({e}). Intentando respaldo...")
            self._download_interstellar_backup()

        # Configuraci√≥n de generaci√≥n por defecto para inicios de cuento.
        # Estos par√°metros buscan un equilibrio entre creatividad y coherencia.
        self.generation_config = GenerationConfig(
            max_length=300,             # Longitud m√°xima total del texto generado (prompt + generaci√≥n)
            do_sample=True,             # Permite muestreo (generaci√≥n aleatoria)
            temperature=1.0,            # Controla la aleatoriedad. 1.0 es un buen balance.
            top_p=0.95,                 # Muestrea de las palabras que suman el 95% de probabilidad acumulada.
            top_k=50,                   # Muestrea de las 50 palabras m√°s probables.
            repetition_penalty=1.2,     # Penaliza la repetici√≥n de tokens para mayor diversidad.
            num_return_sequences=3,     # Genera 3 inicios de cuento para ofrecer opciones.
            pad_token_id=self.tokenizer.eos_token_id, # Tokens especiales para el modelo.
            bos_token_id=self.tokenizer.bos_token_id,
            eos_token_id=self.tokenizer.eos_token_id,
        )

    def _download_interstellar_backup(self):
        """
        Intenta cargar el modelo desde Hugging Face Hub como un respaldo si la carga inicial falla.
        Lanza InterstellarError si la carga de respaldo tambi√©n falla.
        """
        print("üõ∏ Conectando con servidores cu√°nticos de respaldo para la carga del modelo...")
        try:
            self.tokenizer = GPT2Tokenizer.from_pretrained(self.model_name)
            self.model = GPT2LMHeadModel.from_pretrained(self.model_name).to(self.device)
            self.tokenizer.pad_token = self.tokenizer.eos_token
            print("‚úÖ Carga de respaldo exitosa. ¬°Universo narrativo restaurado!")
        except Exception as e:
            raise InterstellarError(f"¬°Fall√≥ la conexi√≥n con el universo alternativo! Error cr√≠tico: {e}\n"
                                    "Aseg√∫rate de tener conexi√≥n a internet o de que el modelo 'DeepESP/gpt2-spanish' est√© disponible.")

    def generate_story_idea(self, theme):
        """
        Genera una idea concisa para un cuento (personaje, escenario o conflicto)
        basada en un tema dado.
        """
        # Variedad de prompts para obtener diferentes tipos de ideas
        prompts = [
            f"Describe un personaje misterioso para un cuento sobre {theme}:",
            f"Prop√≥n un escenario inusual para una historia de {theme}:",
            f"Una idea original para el conflicto principal en un cuento de {theme}:"
        ]
        
        selected_prompt = np.random.choice(prompts) # Elige un prompt al azar
        
        inputs = self.tokenizer(selected_prompt, return_tensors="pt").to(self.device)
        
        print(f"\nüß† Generando idea: '{selected_prompt}'")
        
        try:
            outputs = self.model.generate(
                **inputs,
                max_length=len(inputs["input_ids"][0]) + 60, # Genera hasta 60 tokens adicionales para la idea
                do_sample=True,
                temperature=0.8, # Temperatura moderada para ideas m√°s enfocadas
                top_p=0.95,
                num_return_sequences=1, # Solo necesitamos una idea
                pad_token_id=self.tokenizer.eos_token_id,
                bos_token_id=self.tokenizer.bos_token_id,
                eos_token_id=self.tokenizer.eos_token_id,
            )
            decoded_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
            
            # Limpieza del texto generado: Elimina el prompt y posibles encabezados
            idea = decoded_text.replace(selected_prompt, "", 1).strip()
            idea = re.sub(r'^(?:[0-9]+\.?\s*)?(?:El personaje es:|El escenario es:|El conflicto es:|Una idea es:)\s*', '', idea, flags=re.IGNORECASE).strip()
            
            # Intenta cortar la idea en la primera o segunda oraci√≥n completa para mayor concisi√≥n.
            sentences = re.split(r'(?<=[.?!])\s*', idea)
            if len(sentences) >= 2 and sentences[0].strip() and sentences[1].strip():
                return " ".join(sentences[:2]).strip() # Toma las dos primeras oraciones si existen
            elif sentences and sentences[0].strip():
                return sentences[0].strip() # Si solo hay una, toma esa
            else:
                return idea.split('\n')[0].strip() # Fallback: toma la primera l√≠nea

        except Exception as e:
            return f"‚ùå No se pudo generar una idea: {e}"

    def generate_story_start(self, theme, starting_phrase=""):
        """
        Genera el inicio de un cuento bas√°ndose en un tema y una frase inicial opcional.
        Produce m√∫ltiples opciones de inicio.
        """
        # Crea el prompt base que gu√≠a al modelo para generar un inicio de cuento detallado.
        if starting_phrase:
            base_prompt = f"Escribe un comienzo detallado para un cuento sobre {theme}, iniciando con la frase: '{starting_phrase}'\n"
        else:
            base_prompt = f"Escribe un comienzo detallado para un cuento sobre {theme}:\n"
            
        print(f"\n‚úçÔ∏è Generando inicio de cuento para: '{theme}'")
        if starting_phrase:
            print(f"   (Comenzando con: '{starting_phrase}')")

        inputs = self.tokenizer(base_prompt, return_tensors="pt").to(self.device)
        
        # Calcula la longitud m√°xima permitida para la generaci√≥n, dando amplio margen.
        current_max_length = len(inputs["input_ids"][0]) + 250 # Genera hasta 250 tokens adicionales

        # Actualiza la configuraci√≥n de generaci√≥n para esta llamada si es necesario
        # (Aunque en este caso usa la self.generation_config ya optimizada)
        temp_generation_config = GenerationConfig(
            max_length=current_max_length,
            do_sample=self.generation_config.do_sample,
            temperature=self.generation_config.temperature,
            top_p=self.generation_config.top_p,
            top_k=self.generation_config.top_k,
            repetition_penalty=self.generation_config.repetition_penalty,
            num_return_sequences=self.generation_config.num_return_sequences,
            pad_token_id=self.tokenizer.eos_token_id,
            bos_token_id=self.tokenizer.bos_token_id,
            eos_token_id=self.tokenizer.eos_token_id,
        )

        try:
            outputs = self.model.generate(
                **inputs,
                generation_config=temp_generation_config # Usa la configuraci√≥n temporal
            )
            
            generated_starts = []
            for i, output_sequence in enumerate(outputs):
                decoded_text = self.tokenizer.decode(output_sequence, skip_special_tokens=True)
                
                # Limpia el texto: elimina el prompt inicial y cualquier resto de instrucci√≥n.
                story_start = decoded_text.replace(base_prompt, "", 1).strip()
                story_start = re.sub(r'^(?:Escribe un comienzo detallado para un cuento sobre .*?:)?\s*\n*', '', story_start, flags=re.IGNORECASE | re.MULTILINE).strip()
                
                # Divide el texto en oraciones para un corte m√°s natural.
                sentences = re.split(r'(?<=[.?!])\s+', story_start)
                
                final_text = ""
                # Intenta tomar hasta 3 oraciones completas para un inicio sustancial.
                if len(sentences) >= 3 and sentences[0].strip() and sentences[1].strip() and sentences[2].strip():
                    final_text = " ".join(sentences[:3]).strip()
                    # A√±ade puntos suspensivos si hay m√°s texto despu√©s de las 3 oraciones
                    if len(sentences) > 3 and sentences[3].strip():
                        final_text += "..."
                elif sentences and sentences[0].strip(): # Si hay menos de 3 pero al menos una oraci√≥n
                    final_text = sentences[0].strip() + "..." # Toma la primera y a√±ade puntos suspensivos
                else: # Si el texto generado es muy corto o no tiene oraciones v√°lidas
                    final_text = story_start.strip() + "..." if story_start.strip() else "..."

                generated_starts.append(final_text)
            
            return generated_starts
        except Exception as e:
            return [f"‚ùå No se pudo generar el inicio del cuento: {e}"]

# --------------------------------------
# PUNTO DE ENTRADA DEL PROGRAMA
# --------------------------------------
if __name__ == "__main__":
    print("""
    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïó     ‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó 
    ‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïê‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïê‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó
    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù
    ‚ïö‚ïê‚ïê‚ïê‚ïê‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë     ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù  ‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó
    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë   ‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù   ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë
    ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù   ‚ïö‚ïê‚ïù    ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù    ‚ïö‚ïê‚ïù   ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù
    GENERADOR DE CUENTOS M√ÅGICOS V-1.2 (Optimizado para GitHub)
    """)

    try:
        storyteller = StorytellerGPT()
    except InterstellarError as e:
        print(f"¬°ERROR CR√çTICO AL INICIAR!: {e}")
        print("El generador no puede funcionar sin el modelo. Saliendo del programa.")
        exit()
    except Exception as e:
        print(f"Ocurri√≥ un error inesperado al inicializar el generador: {e}")
        print("Saliendo del programa.")
        exit()
        
    while True:
        print("\n--- ELIGE TU AVENTURA NARRATIVA ---")
        print("1. Generar una **idea** para un cuento (personaje, escenario, conflicto)")
        print("2. Generar el **inicio** de un cuento (un p√°rrafo o m√°s)")
        print("3. Salir del Generador")
        
        choice = input("üëâ ¬øQu√© quieres hacer? (1/2/3): ")

        if choice == '1':
            theme = input("üåü Tema de la idea (ej: 'un viaje en el tiempo', 'un detective sobrenatural'): ")
            if not theme:
                print("‚ö†Ô∏è Por favor, introduce un tema v√°lido.")
                continue
            idea = storyteller.generate_story_idea(theme)
            print(f"\nüí° IDEA GENERADA:\n{idea}")
            print("‚ïê"*40)

        elif choice == '2':
            theme = input("üìö Tema del cuento (ej: 'la √∫ltima colonia en Marte', 'un reino de sombras'): ")
            if not theme:
                print("‚ö†Ô∏è Por favor, introduce un tema v√°lido.")
                continue
            starting_phrase = input("‚úçÔ∏è Frase con la que quieres que empiece (opcional, deja vac√≠o para que la cree): ")
            
            story_starts = storyteller.generate_story_start(theme, starting_phrase)
            
            print("\nüìñ INICIOS DE CUENTO GENERADOS:")
            for i, start in enumerate(story_starts):
                print(f"--- OPCI√ìN {i+1} ---")
                print(start)
                print("-" * 15)
            print("‚ïê"*40)

        elif choice == '3':
            print("\n‚ú® ¬°El universo narrativo te espera! ¬°Adi√≥s y felices historias!")
            break
        else:
            print("üö´ Opci√≥n no v√°lida. Por favor, elige 1, 2 o 3.")
